{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYMDvmxFZBrC3qvVcZ3azl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazaqa0901/ML_test/blob/main/test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GL09-Ub-9e6A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import time\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "j5dNavOw9idv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae94fbf-7c3e-44bd-d2b9-c74c390a9f3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_file_name = '/content/drive/MyDrive/Dataset.zip'\n",
        "extraction_dir = '/content/dataset'\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extraction_dir)"
      ],
      "metadata": {
        "id": "j92-6h_N9i56"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- ì„¤ì • ---\n",
        "DATA_ROOT = '/content/dataset/Dataset/Train' # ë°ì´í„°ê°€ ìˆëŠ” ë£¨íŠ¸ í´ë”\n",
        "SAMPLE_SIZE_FOR_SIZE_CHECK = 1000 # í¬ê¸° ë¶„ì„ì„ ìœ„í•´ ëª‡ ì¥ì„ ìƒ˜í”Œë§í• ì§€\n",
        "\n",
        "# ì´ë¯¸ì§€ë¡œ ê°„ì£¼í•  í™•ì¥ìë“¤\n",
        "IMAGE_EXTS = {'.jpg'}\n",
        "\n",
        "def analyze_folder(folder_path):\n",
        "    \"\"\"\n",
        "    í´ë” ë‚´ì˜ íŒŒì¼ ê°œìˆ˜, í™•ì¥ì ë¶„í¬, ê·¸ë¦¬ê³  ì´ë¯¸ì§€ í¬ê¸° í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(folder_path):\n",
        "        return None\n",
        "\n",
        "    total_files = 0\n",
        "    extension_counts = Counter()\n",
        "    all_image_paths = []\n",
        "\n",
        "    # 1. íŒŒì¼ ìŠ¤ìº” (os.walkë¡œ êµ¬ì„êµ¬ì„ ì°¾ê¸°)\n",
        "    print(f\"   ğŸ“‚ ìŠ¤ìº” ì¤‘... '{os.path.basename(folder_path)}'\")\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            total_files += 1\n",
        "            ext = os.path.splitext(file)[1].lower()\n",
        "            extension_counts[ext] += 1\n",
        "\n",
        "            if ext in IMAGE_EXTS:\n",
        "                all_image_paths.append(os.path.join(root, file))\n",
        "\n",
        "    # 2. ì´ë¯¸ì§€ í¬ê¸° ë¶„ì„ (ìƒ˜í”Œë§)\n",
        "    width_stats = {'min': 0, 'max': 0, 'mean': 0}\n",
        "    height_stats = {'min': 0, 'max': 0, 'mean': 0}\n",
        "\n",
        "    if all_image_paths:\n",
        "        # ìƒ˜í”Œë§ (ì „ì²´ ê°œìˆ˜ê°€ ìƒ˜í”Œ ìˆ˜ë³´ë‹¤ ì ìœ¼ë©´ ì „ì²´ ì‚¬ìš©)\n",
        "        if len(all_image_paths) > SAMPLE_SIZE_FOR_SIZE_CHECK:\n",
        "            sampled_paths = random.sample(all_image_paths, SAMPLE_SIZE_FOR_SIZE_CHECK)\n",
        "        else:\n",
        "            sampled_paths = all_image_paths\n",
        "\n",
        "        widths = []\n",
        "        heights = []\n",
        "\n",
        "        for img_path in tqdm(sampled_paths, desc=f\"   ğŸ“ í¬ê¸° ì¸¡ì • ì¤‘ ({len(sampled_paths)}ì¥)\", leave=False):\n",
        "            try:\n",
        "                with Image.open(img_path) as img:\n",
        "                    w, h = img.size\n",
        "                    widths.append(w)\n",
        "                    heights.append(h)\n",
        "            except Exception:\n",
        "                pass # ê¹¨ì§„ ì´ë¯¸ì§€ëŠ” ë¬´ì‹œ\n",
        "\n",
        "        if widths:\n",
        "            widths = np.array(widths)\n",
        "            heights = np.array(heights)\n",
        "            width_stats = {'min': widths.min(), 'max': widths.max(), 'mean': widths.mean()}\n",
        "            height_stats = {'min': heights.min(), 'max': heights.max(), 'mean': heights.mean()}\n",
        "\n",
        "    return {\n",
        "        'total': total_files,\n",
        "        'exts': extension_counts,\n",
        "        'w_stats': width_stats,\n",
        "        'h_stats': height_stats,\n",
        "        'img_count': len(all_image_paths) # ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜\n",
        "    }\n",
        "\n",
        "def main():\n",
        "    print(f\"=== ë°ì´í„°ì…‹ ì •ë°€ ë¶„ì„ (ê°œìˆ˜ + í¬ê¸°) ===\")\n",
        "    print(f\"ëŒ€ìƒ ê²½ë¡œ: {os.path.abspath(DATA_ROOT)}\\n\")\n",
        "\n",
        "    if not os.path.exists(DATA_ROOT):\n",
        "        print(f\"âŒ ì˜¤ë¥˜: '{DATA_ROOT}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        subfolders = [f for f in os.listdir(DATA_ROOT) if os.path.isdir(os.path.join(DATA_ROOT, f))]\n",
        "        subfolders.sort()\n",
        "    except Exception as e:\n",
        "        print(f\"ì˜¤ë¥˜: {e}\")\n",
        "        return\n",
        "\n",
        "    if not subfolders:\n",
        "        print(\"âŒ í•˜ìœ„ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    print(f\"{'í´ë”ëª…':<12} | {'íŒŒì¼ ìˆ˜':<9} | {'ì´ë¯¸ì§€ ìˆ˜':<9} | {'í‰ê·  í¬ê¸° (WxH)':<18} | {'í™•ì¥ì ë¶„í¬'}\")\n",
        "    print(\"-\" * 95)\n",
        "\n",
        "    total_images_sum = 0\n",
        "\n",
        "    for folder in subfolders:\n",
        "        folder_path = os.path.join(DATA_ROOT, folder)\n",
        "        result = analyze_folder(folder_path)\n",
        "\n",
        "        if result is None:\n",
        "            print(f\"{folder:<12} | {'ê²½ë¡œ ì—†ìŒ':<9} |\")\n",
        "            continue\n",
        "\n",
        "        # ê²°ê³¼ í¬ë§¤íŒ…\n",
        "        count_str = f\"{result['total']:,}\"\n",
        "        img_count_str = f\"{result['img_count']:,}\"\n",
        "\n",
        "        w_mean = result['w_stats']['mean']\n",
        "        h_mean = result['h_stats']['mean']\n",
        "        size_str = f\"{w_mean:.0f}x{h_mean:.0f}\" if w_mean > 0 else \"N/A\"\n",
        "\n",
        "        # ì£¼ìš” í™•ì¥ìë§Œ í‘œì‹œ (ìƒìœ„ 3ê°œ)\n",
        "        top_exts = result['exts'].most_common(3)\n",
        "        ext_str = \", \".join([f\"{k} {v}\" for k, v in top_exts])\n",
        "\n",
        "        print(f\"{folder:<12} | {count_str:<9} | {img_count_str:<9} | {size_str:<18} | {ext_str}\")\n",
        "\n",
        "        total_images_sum += result['img_count']\n",
        "\n",
        "    print(\"-\" * 95)\n",
        "    print(f\"ì´ ì´ë¯¸ì§€ íŒŒì¼ í•©ê³„: {total_images_sum:,} ì¥\")\n",
        "    print(\"â€» í‰ê·  í¬ê¸°ëŠ” í´ë”ë³„ ìµœëŒ€ 1,000ì¥ ìƒ˜í”Œë§ ê¸°ì¤€ì…ë‹ˆë‹¤.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZKqnshetqcQ",
        "outputId": "16bb44a1-981b-42c6-eef4-4a7eb6e24e4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ë°ì´í„°ì…‹ ì •ë°€ ë¶„ì„ (ê°œìˆ˜ + í¬ê¸°) ===\n",
            "ëŒ€ìƒ ê²½ë¡œ: /content/dataset/Dataset/Train\n",
            "\n",
            "í´ë”ëª…          | íŒŒì¼ ìˆ˜      | ì´ë¯¸ì§€ ìˆ˜     | í‰ê·  í¬ê¸° (WxH)        | í™•ì¥ì ë¶„í¬\n",
            "-----------------------------------------------------------------------------------------------\n",
            "   ğŸ“‚ ìŠ¤ìº” ì¤‘... 'Fake'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake         | 70,001    | 70,001    | 256x256            | .jpg 70001\n",
            "   ğŸ“‚ ìŠ¤ìº” ì¤‘... 'Real'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real         | 70,001    | 70,001    | 256x256            | .jpg 70001\n",
            "-----------------------------------------------------------------------------------------------\n",
            "ì´ ì´ë¯¸ì§€ íŒŒì¼ í•©ê³„: 140,002 ì¥\n",
            "â€» í‰ê·  í¬ê¸°ëŠ” í´ë”ë³„ ìµœëŒ€ 1,000ì¥ ìƒ˜í”Œë§ ê¸°ì¤€ì…ë‹ˆë‹¤.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- ì„¤ì • ---\n",
        "SOURCE_DATA_DIR = '/content/dataset/Dataset/Train'\n",
        "DEST_DIR = './deepfake_60k_224px' # ìƒˆë¡œ ë§Œë“¤ì–´ì§ˆ í´ë” ì´ë¦„\n",
        "TARGET_SIZE = 224 # ëª©í‘œ í¬ê¸°\n",
        "TARGET_REAL_SAMPLES = 10000 # Real í´ë”ë‹¹ ìƒ˜í”Œë§ ê°œìˆ˜\n",
        "TARGET_FAKE_SAMPLES = 10000 # Fake í´ë”ë‹¹ ìƒ˜í”Œë§ ê°œìˆ˜\n",
        "\n",
        "# ì´ë¯¸ì§€ í™•ì¥ì ì •ì˜\n",
        "VALID_EXTENSIONS = ('.jpg',)\n",
        "\n",
        "def resize_with_pad(img, target_size):\n",
        "    \"\"\"\n",
        "    ì´ë¯¸ì§€ë¥¼ target_size x target_size ìº”ë²„ìŠ¤ ì¤‘ì•™ì—\n",
        "    ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì§•í•˜ì—¬ ë¶™ì—¬ë„£ìŠµë‹ˆë‹¤ (ê²€ì€ìƒ‰ íŒ¨ë”©).\n",
        "    \"\"\"\n",
        "    # RGBA(íˆ¬ëª…)ì¸ ê²½ìš° RGBë¡œ ë³€í™˜ (ì €ì¥ ì‹œ ì˜¤ë¥˜ ë°©ì§€)\n",
        "    if img.mode == 'RGBA':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    w, h = img.size\n",
        "\n",
        "    # ë¹„ìœ¨ ìœ ì§€ ë¦¬ì‚¬ì´ì¦ˆ ê³„ì‚°\n",
        "    scale = target_size / max(w, h)\n",
        "    new_w = int(w * scale)\n",
        "    new_h = int(h * scale)\n",
        "\n",
        "    # ë¦¬ì‚¬ì´ì§• (LANCZOS: ê³ í’ˆì§ˆ)\n",
        "    img_resized = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "\n",
        "    # ê²€ì€ìƒ‰ ë°°ê²½ ìƒì„±\n",
        "    new_img = Image.new(\"RGB\", (target_size, target_size), (0, 0, 0))\n",
        "\n",
        "    # ì¤‘ì•™ ì¢Œí‘œ ê³„ì‚°\n",
        "    paste_x = (target_size - new_w) // 2\n",
        "    paste_y = (target_size - new_h) // 2\n",
        "\n",
        "    # ë¶™ì—¬ë„£ê¸°\n",
        "    new_img.paste(img_resized, (paste_x, paste_y))\n",
        "\n",
        "    return new_img\n",
        "\n",
        "def find_all_images(root_dir):\n",
        "    \"\"\"os.walkë¡œ ëª¨ë“  í•˜ìœ„ ì´ë¯¸ì§€ ì°¾ê¸°\"\"\"\n",
        "    image_list = []\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(VALID_EXTENSIONS):\n",
        "                image_list.append(os.path.join(root, file))\n",
        "    return image_list\n",
        "\n",
        "def main():\n",
        "    print(f\"=== ë°ì´í„° ì „ì²˜ë¦¬(224px) ë° ì €ì¥ ì‹œì‘ ===\")\n",
        "\n",
        "    # ëª©ì ì§€ í´ë” ì´ˆê¸°í™”\n",
        "    if os.path.exists(DEST_DIR):\n",
        "        print(f\"ê¸°ì¡´ '{DEST_DIR}' í´ë” ì‚­ì œ ì¤‘...\")\n",
        "        shutil.rmtree(DEST_DIR)\n",
        "\n",
        "    os.makedirs(os.path.join(DEST_DIR, 'face_real'))\n",
        "    os.makedirs(os.path.join(DEST_DIR, 'face_fake'))\n",
        "\n",
        "    # --- 1. ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘ ---\n",
        "    print(\"\\n[1ë‹¨ê³„] ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘ ë° ìƒ˜í”Œë§...\")\n",
        "\n",
        "    # (1) Real\n",
        "    wiki_path = os.path.join(SOURCE_DATA_DIR, 'Real')\n",
        "    real_paths = find_all_images(wiki_path)\n",
        "    print(f\"  - Real: {len(real_paths)}ì¥ ë°œê²¬\")\n",
        "\n",
        "    if len(real_paths) > TARGET_REAL_SAMPLES:\n",
        "        real_paths = np.random.choice(real_paths, TARGET_REAL_SAMPLES, replace=False)\n",
        "    else:\n",
        "        real_paths = real_paths\n",
        "    real_paths = real_paths.tolist() # numpy arrayë¥¼ listë¡œ ë³€í™˜\n",
        "    print(f\"  - Real ìƒ˜í”Œë§: {len(real_paths)}ì¥ ì„ íƒ\")\n",
        "\n",
        "    # (2) Fake\n",
        "    fake_data_path = os.path.join(SOURCE_DATA_DIR, 'Fake')\n",
        "    fake_paths = find_all_images(fake_data_path)\n",
        "    print(f\"  - Fake: {len(fake_paths)}ì¥ ë°œê²¬\")\n",
        "\n",
        "    if len(fake_paths) > TARGET_FAKE_SAMPLES:\n",
        "        fake_paths = np.random.choice(fake_paths, TARGET_FAKE_SAMPLES, replace=False)\n",
        "    else:\n",
        "        fake_paths = fake_paths\n",
        "    fake_paths = fake_paths.tolist() # numpy arrayë¥¼ listë¡œ ë³€í™˜\n",
        "    print(f\"  - Fake ìƒ˜í”Œë§: {len(fake_paths)}ì¥ ì„ íƒ\")\n",
        "\n",
        "    \"\"\"\n",
        "    fake_categories = ['inpainting', 'insight', 'text2img']\n",
        "    fake_copy_list = [] # (ì›ë³¸ê²½ë¡œ, ì €ì¥ë íŒŒì¼ëª…)\n",
        "\n",
        "    for cat in fake_categories:\n",
        "        cat_path = os.path.join(SOURCE_DATA_DIR, cat)\n",
        "        cat_images = find_all_images(cat_path)\n",
        "        print(f\"  - Fake ({cat}): {len(cat_images)}ì¥ ë°œê²¬\")\n",
        "\n",
        "        # ìƒ˜í”Œë§\n",
        "        if len(cat_images) >= TARGET_FAKE_PER_FOLDER:\n",
        "            sampled = np.random.choice(cat_images, TARGET_FAKE_PER_FOLDER, replace=False).tolist()\n",
        "        else:\n",
        "            print(f\"    âš ï¸ {cat}: 1ë§Œì¥ ë¶€ì¡± -> ì „ì²´ ì‚¬ìš©\")\n",
        "            sampled = cat_images\n",
        "\n",
        "        for src_path in sampled:\n",
        "            filename = os.path.basename(src_path)\n",
        "            # íŒŒì¼ëª… ì¶©ëŒ ë°©ì§€\n",
        "            new_filename = f\"{cat}_{filename}\"\n",
        "            # í™•ì¥ìë¥¼ .jpgë¡œ í†µì¼ (ì„ íƒì‚¬í•­)\n",
        "            name_only = os.path.splitext(new_filename)[0]\n",
        "            new_filename = f\"{name_only}.jpg\"\n",
        "\n",
        "            fake_copy_list.append((src_path, new_filename))\"\"\"\n",
        "\n",
        "    total_files = len(real_paths) + len(fake_paths)\n",
        "    print(f\"\\n  => ì´ ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {total_files}ì¥\")\n",
        "\n",
        "    # --- 2. ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì €ì¥ ---\n",
        "    print(\"\\n[2ë‹¨ê³„] ë¦¬ì‚¬ì´ì§•(224x224) ë° ì €ì¥ ì‹œì‘...\")\n",
        "\n",
        "    # (1) Real ì²˜ë¦¬\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "\n",
        "    for src_path in tqdm(real_paths, desc=\"Processing Real\"):\n",
        "        try:\n",
        "            with Image.open(src_path) as img:\n",
        "                # ë¦¬ì‚¬ì´ì¦ˆ + íŒ¨ë”© í•¨ìˆ˜ í˜¸ì¶œ\n",
        "                processed_img = resize_with_pad(img, TARGET_SIZE)\n",
        "\n",
        "                # ì €ì¥ ê²½ë¡œ\n",
        "                filename = os.path.basename(src_path)\n",
        "                name_only = os.path.splitext(filename)[0]\n",
        "                save_name = f\"{name_only}.jpg\" # jpgë¡œ í†µì¼\n",
        "                dst_path = os.path.join(DEST_DIR, 'face_real', save_name)\n",
        "\n",
        "                # ì €ì¥ (ì••ì¶•ë¥  90 ì •ë„ë©´ í™”ì§ˆ ì¢‹ìŒ)\n",
        "                processed_img.save(dst_path, quality=95)\n",
        "                success_count += 1\n",
        "        except Exception as e:\n",
        "            # print(f\"Error processing {src_path}: {e}\")\n",
        "            error_count += 1\n",
        "\n",
        "    # (2) Fake ì²˜ë¦¬\n",
        "    for src_path in tqdm(fake_paths, desc=\"Processing Fake\"):\n",
        "        try:\n",
        "            with Image.open(src_path) as img:\n",
        "                # ì´ë¯¸ 512x512ë¼ë„ 224x224ë¡œ ì¤„ì„\n",
        "                processed_img = resize_with_pad(img, TARGET_SIZE)\n",
        "\n",
        "                filename = os.path.basename(src_path)\n",
        "                name_only = os.path.splitext(filename)[0]\n",
        "                save_name = f\"{name_only}.jpg\" # jpgë¡œ í†µì¼\n",
        "                dst_path = os.path.join(DEST_DIR, 'face_fake', save_name)\n",
        "\n",
        "                processed_img.save(dst_path, quality=95)\n",
        "                success_count += 1\n",
        "        except Exception as e:\n",
        "            error_count += 1\n",
        "\n",
        "    print(f\"\\n=== ì‘ì—… ì™„ë£Œ! ===\")\n",
        "    print(f\"ì„±ê³µ: {success_count}ì¥, ì‹¤íŒ¨: {error_count}ì¥\")\n",
        "    print(f\"ì €ì¥ ìœ„ì¹˜: {os.path.abspath(DEST_DIR)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY7NFqjJufX-",
        "outputId": "18797067-f2c4-4b9c-f0d0-20e2cd4a09cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ë°ì´í„° ì „ì²˜ë¦¬(224px) ë° ì €ì¥ ì‹œì‘ ===\n",
            "ê¸°ì¡´ './deepfake_60k_224px' í´ë” ì‚­ì œ ì¤‘...\n",
            "\n",
            "[1ë‹¨ê³„] ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘ ë° ìƒ˜í”Œë§...\n",
            "  - Real: 70001ì¥ ë°œê²¬\n",
            "  - Real ìƒ˜í”Œë§: 10000ì¥ ì„ íƒ\n",
            "  - Fake: 70001ì¥ ë°œê²¬\n",
            "  - Fake ìƒ˜í”Œë§: 10000ì¥ ì„ íƒ\n",
            "\n",
            "  => ì´ ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: 20000ì¥\n",
            "\n",
            "[2ë‹¨ê³„] ë¦¬ì‚¬ì´ì§•(224x224) ë° ì €ì¥ ì‹œì‘...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Real: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:59<00:00, 169.11it/s]\n",
            "Processing Fake: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [01:02<00:00, 161.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ì‘ì—… ì™„ë£Œ! ===\n",
            "ì„±ê³µ: 20000ì¥, ì‹¤íŒ¨: 0ì¥\n",
            "ì €ì¥ ìœ„ì¹˜: /content/deepfake_60k_224px\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "NUM_SAMPLES = 20000\n",
        "LEARNING_RATE = 5e-5\n",
        "PATIENCE = 5"
      ],
      "metadata": {
        "id": "vXSR9lRr-BUV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResizeWithPad:\n",
        "    def __init__(self, target_size):\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "\n",
        "        scale = self.target_size / max(w, h)\n",
        "\n",
        "        new_w = int(w * scale)\n",
        "        new_h = int(h * scale)\n",
        "\n",
        "        # ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ\n",
        "        resized_img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "\n",
        "        # ê²€ì€ìƒ‰ ìº”ë²„ìŠ¤ ìƒì„±\n",
        "        canvas = Image.new(\"RGB\", (self.target_size, self.target_size), (0, 0, 0))\n",
        "\n",
        "        # ìº”ë²„ìŠ¤ ì¤‘ì•™ì— ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ë°°ì¹˜\n",
        "        pad_x = (self.target_size - new_w) // 2\n",
        "        pad_y = (self.target_size - new_h) // 2\n",
        "\n",
        "        canvas.paste(resized_img, (pad_x, pad_y))\n",
        "\n",
        "        return canvas"
      ],
      "metadata": {
        "id": "I-6_tqLl9igO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, paths, labels, transform=None):\n",
        "        self.resizer = ResizeWithPad(224)\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # ë””ìŠ¤í¬ì—ì„œ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ì´ë¯¸ì§€ ë¡œë“œ (PIL)\n",
        "        img_path = self.paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        image = self.resizer(image)\n",
        "\n",
        "\n",
        "        return image\"\"\""
      ],
      "metadata": {
        "id": "qDuryj259ilG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1c347645"
      },
      "outputs": [],
      "source": [
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "class RAMDataset(Dataset):\n",
        "    def __init__(self, images_uint8, labels, transform=None):\n",
        "        self.images = images_uint8 # (N, C, H, W) uint8 tensor\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        # ì •ê·œí™”ìš© transform (ì—¬ê¸°ì„œ floatë³€í™˜ ë° ì •ê·œí™” ìˆ˜í–‰)\n",
        "        self.normalize = transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    def __getitem__(self, idx):\n",
        "        # 1. uint8 í…ì„œ ê°€ì ¸ì˜¤ê¸°\n",
        "        img = self.images[idx]\n",
        "\n",
        "        # 2. float32ë¡œ ë³€í™˜ ë° 0~1 ìŠ¤ì¼€ì¼ë§ (ë§¤ìš° ë¹ ë¦„)\n",
        "        img = img.float() / 255.0\n",
        "\n",
        "        # 3. ì •ê·œí™” ì ìš©\n",
        "        img = self.normalize(img)\n",
        "\n",
        "        # 4. ì¶”ê°€ ì¦ê°•(Augmentation)ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ ì ìš© ê°€ëŠ¥\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "\n",
        "def load_images_to_ram_uint8(paths):\n",
        "    \"\"\"\n",
        "    ì´ë¯¸ì§€ë¥¼ ì½ì–´ì„œ ë¦¬ì‚¬ì´ì¦ˆ í›„ uint8 í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥\n",
        "    \"\"\"\n",
        "    to_tensor = transforms.PILToTensor() # uint8 ìœ ì§€ (0-255)\n",
        "    resizer = ResizeWithPad(224)\n",
        "\n",
        "    tensor_list = []\n",
        "    print(f\"Loading {len(paths)} images to RAM (uint8 mode)...\")\n",
        "\n",
        "    for path in tqdm(paths):\n",
        "        try:\n",
        "            img = Image.open(path).convert('RGB')\n",
        "            img = resizer(img)\n",
        "            tensor = to_tensor(img) # (3, 224, 224) uint8 Tensor\n",
        "            tensor_list.append(tensor)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {path}: {e}\")\n",
        "\n",
        "\n",
        "    return torch.stack(tensor_list) # (N, 3, 224, 224) uint8 Tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNetLike(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(AlexNetLike, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Conv 1\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2), # 224 -> 55\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 55 -> 27\n",
        "\n",
        "            # Conv 2\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2), # 27 -> 27\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 27 -> 13\n",
        "\n",
        "            # Conv 3\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv 4\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv 5\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 13 -> 6\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 6 * 6, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, num_classes) # num_classes=1\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x); x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1); x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "WFqz2Y8P9iuf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model_name, device):\n",
        "\n",
        "    model = None\n",
        "    num_classes = 1 # ì´ì§„ ë¶„ë¥˜ (Real/Fake)\n",
        "\n",
        "    print(f\"Loading {model_name} architecture (FROM SCRATCH)...\")\n",
        "\n",
        "    if model_name.lower() == 'alexnet':\n",
        "        # ì§ì ‘ ì§  AlexNet (Conv 5, FC 3)\n",
        "        model =  AlexNetLike(num_classes=num_classes)\n",
        "\n",
        "    elif model_name.lower() == 'vgg16':\n",
        "        # VGG16\n",
        "        model = models.vgg16(weights=None, num_classes=num_classes)\n",
        "\n",
        "    elif model_name.lower() == 'googlenet':\n",
        "        # GoogLeNet\n",
        "        model = models.googlenet(weights=None, num_classes=num_classes, aux_logits=False)\n",
        "\n",
        "    elif model_name.lower() == 'resnet50':\n",
        "        # ResNet50\n",
        "        model = models.resnet50(weights=None, num_classes=num_classes)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {model_name}. Choose from 'alexnet, 'vgg16', 'googlenet', 'resnet50'\")\n",
        "\n",
        "    return model.to(device)"
      ],
      "metadata": {
        "id": "opsguJzt9izn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1989208d"
      },
      "outputs": [],
      "source": [
        "# í•™ìŠµ\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs, patience):\n",
        "    print(\"=== í•™ìŠµ ì‹œì‘ ===\")\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_weights = None\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # --- í›ˆë ¨ ---\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        # tqdmìœ¼ë¡œ ì§„í–‰ ìƒí™© í‘œì‹œ\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
        "\n",
        "        for images, labels in train_pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # ìˆœì „íŒŒ\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # ì—­ì „íŒŒ ë° ìµœì í™”\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # ì •í™•ë„ ê³„ì‚°\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "\n",
        "            train_pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_train_acc = correct_train / total_train\n",
        "\n",
        "        # --- ê²€ì¦ ---\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
        "            for images, labels in val_pbar:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_val_loss += loss.item() * images.size(0)\n",
        "\n",
        "                preds = torch.sigmoid(outputs) > 0.5\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (preds == labels).sum().item()\n",
        "\n",
        "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
        "        epoch_val_acc = correct_val / total_val\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - {elapsed_time:.0f}s - \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f} - \"\n",
        "              f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
        "\n",
        "        # --- Early Stopping ë° Best Model ì €ì¥ ---\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            print(f\"  Validation loss decreased ({best_val_loss:.4f} --> {epoch_val_loss:.4f}). Saving model...\")\n",
        "            best_val_loss = epoch_val_loss\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model_weights, MODEL_SAVE_PATH)\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"  Validation loss did not improve. Patience: {epochs_no_improve}/{patience}\")\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "            break\n",
        "\n",
        "    print(\"=== í•™ìŠµ ì™„ë£Œ ===\")\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í‰ê°€\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_test_loss = 0.0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    print(\"\\n=== í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€ ì‹œì‘ ===\")\n",
        "    with torch.no_grad():\n",
        "        test_pbar = tqdm(test_loader, desc=\"[Test]\", leave=False)\n",
        "        for images, labels in test_pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_test_loss += loss.item() * images.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (preds == labels).sum().item()\n",
        "\n",
        "    test_loss = running_test_loss / len(test_loader.dataset)\n",
        "    test_acc = correct_test / total_test\n",
        "\n",
        "    print(f\"===== ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ =====\")\n",
        "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "9bPDf2Ww9i3m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë©”ì¸ ì‹¤í–‰\n",
        "start_time = time.time()\n",
        "\n",
        "# GPU ì„¤ì •\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ë°ì´í„° ê²½ë¡œ ë° ë¼ë²¨ ìˆ˜ì§‘\n",
        "Fake_PATH = \"/content/dataset/Dataset/Train/Fake\"\n",
        "Real_PATH = \"/content/dataset/Dataset/Train/Real\"\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/ML/deepfake_baseline_model.pth\"\n",
        "print(\"ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘ ì¤‘...\")\n",
        "face_real_dir = os.path.join(Real_PATH)\n",
        "face_fake_dir = os.path.join(Fake_PATH)\n",
        "\n",
        "real_paths = glob.glob(os.path.join(face_real_dir, \"*.*\"))\n",
        "fake_paths = glob.glob(os.path.join(face_fake_dir, \"*.*\"))\n",
        "\n",
        "all_paths = real_paths + fake_paths\n",
        "all_labels = [0] * len(real_paths) + [1] * len(fake_paths)\n",
        "\n",
        "print(f\"ì´ {len(all_labels)}ê°œ ì´ë¯¸ì§€ ê²½ë¡œ ë°œê²¬.\")\n",
        "# ìƒ˜í”Œ ê°œìˆ˜ ì œí•œ\n",
        "NUM_SAMPLES = min(NUM_SAMPLES, len(all_paths))\n",
        "\n",
        "print(f\"{NUM_SAMPLES}ê°œ ìƒ˜í”Œì„ ìƒ˜í”Œë§...\")\n",
        "_, target_paths, _, target_labels = train_test_split(\n",
        "    all_paths, all_labels,\n",
        "    test_size= NUM_SAMPLES,\n",
        "    random_state=42,\n",
        "    stratify=all_labels\n",
        ")\n",
        "print(f\"ìƒ˜í”Œë§ ì™„ë£Œ: {NUM_SAMPLES}ê°œ ì´ë¯¸ì§€ ì„ íƒ.\")"
      ],
      "metadata": {
        "id": "TQdrB4Mh-BKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc39f25-527c-4e0f-e0fb-85fe7884587a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘ ì¤‘...\n",
            "ì´ 140002ê°œ ì´ë¯¸ì§€ ê²½ë¡œ ë°œê²¬.\n",
            "20000ê°œ ìƒ˜í”Œì„ ìƒ˜í”Œë§...\n",
            "ìƒ˜í”Œë§ ì™„ë£Œ: 20000ê°œ ì´ë¯¸ì§€ ì„ íƒ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ë°ì´í„°ë¥¼ 7:2:1 ë¹„ìœ¨ë¡œ ë¶„í• í•©ë‹ˆë‹¤...\")\n",
        "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "    target_paths, target_labels, test_size=0.3, random_state=42, stratify=target_labels\n",
        ")\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "    temp_paths, temp_labels, test_size=(1/3), random_state=42, stratify=temp_labels\n",
        ")\n",
        "print(f\"ë¶„í•  ì™„ë£Œ: Train {len(train_paths)}ê°œ, Validation {len(val_paths)}ê°œ, Test {len(test_paths)}ê°œ\")"
      ],
      "metadata": {
        "id": "CdMnbU6J-BIe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f55a258-d8c3-4ed8-f8c3-1079393fcc61"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë°ì´í„°ë¥¼ 7:2:1 ë¹„ìœ¨ë¡œ ë¶„í• í•©ë‹ˆë‹¤...\n",
            "ë¶„í•  ì™„ë£Œ: Train 14000ê°œ, Validation 4000ê°œ, Test 2000ê°œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° ì „ì²˜ë¦¬ ë° RAMì— ë¡œë“œ\n",
        "print(\"ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (ëª¨ë“  ë°ì´í„°ë¥¼ RAMì— ë¡œë“œ)...\")\n",
        "\n",
        "# ëª¨ë“  ë°ì´í„°ë¥¼ RAMìœ¼ë¡œ ë¡œë“œ\n",
        "X_train = load_images_to_ram_uint8(train_paths)\n",
        "y_train = torch.tensor(train_labels, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_val = load_images_to_ram_uint8(val_paths)\n",
        "y_val = torch.tensor(val_labels, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_test = load_images_to_ram_uint8(test_paths)\n",
        "y_test = torch.tensor(test_labels, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "print(\"ëª¨ë“  ë°ì´í„°ë¥¼ RAMì— ë¡œë“œ ì™„ë£Œ.\")\n",
        "\n",
        "# RAM ê¸°ë°˜ì˜ TensorDatasetê³¼ DataLoader ìƒì„±\n",
        "train_dataset = RAMDataset(X_train, y_train, transform=None)\n",
        "val_dataset = RAMDataset(X_val, y_val, transform=None)\n",
        "test_dataset = RAMDataset(X_test, y_test, transform=None)\n",
        "\n",
        "# RAMì—ì„œ ì½ìœ¼ë¯€ë¡œ num_workers=0, pin_memory=False (ì´ë¯¸ RAMì— ìˆìŒ)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ.\")"
      ],
      "metadata": {
        "id": "b2bGm-Z--BFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9293d76f-ead6-438d-a42f-5346011bc585"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (ëª¨ë“  ë°ì´í„°ë¥¼ RAMì— ë¡œë“œ)...\n",
            "Loading 14000 images to RAM (uint8 mode)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14000/14000 [01:23<00:00, 168.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 4000 images to RAM (uint8 mode)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [00:22<00:00, 176.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 2000 images to RAM (uint8 mode)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:08<00:00, 223.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëª¨ë“  ë°ì´í„°ë¥¼ RAMì— ë¡œë“œ ì™„ë£Œ.\n",
            "ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "# 8. ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
        "model = get_model('alexnet', device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 9. í•™ìŠµ ë° í‰ê°€\n",
        "model = train_model(model, train_loader, val_loader, criterion, optimizer, device, EPOCHS, PATIENCE)\n",
        "evaluate_model(model, test_loader,\n",
        "               criterion, device)\n",
        "\n",
        "print(f\"ì´ ì‹¤í–‰ ì‹œê°„: {(time.time() - start_time) / 60:.2f} ë¶„\")"
      ],
      "metadata": {
        "id": "aZnszUtP-BAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca1890a-9234-4a18-dcf0-ced03352c136"
      },
      "execution_count": 22,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading alexnet architecture (FROM SCRATCH)...\n",
            "=== í•™ìŠµ ì‹œì‘ ===\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30 - 2480s - Train Loss: 0.5613, Train Acc: 0.7006 - Val Loss: 0.6306, Val Acc: 0.7033\n",
            "  Validation loss decreased (inf --> 0.6306). Saving model...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/30 - 2486s - Train Loss: 0.3528, Train Acc: 0.8440 - Val Loss: 0.3731, Val Acc: 0.8407\n",
            "  Validation loss decreased (0.6306 --> 0.3731). Saving model...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/30 - 2530s - Train Loss: 0.2546, Train Acc: 0.8935 - Val Loss: 0.2990, Val Acc: 0.8762\n",
            "  Validation loss decreased (0.3731 --> 0.2990). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - 2596s - Train Loss: 0.1887, Train Acc: 0.9236 - Val Loss: 0.2119, Val Acc: 0.9175\n",
            "  Validation loss decreased (0.2990 --> 0.2119). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - 2597s - Train Loss: 0.1498, Train Acc: 0.9415 - Val Loss: 0.4602, Val Acc: 0.8390\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - 2687s - Train Loss: 0.1238, Train Acc: 0.9486 - Val Loss: 0.2326, Val Acc: 0.9140\n",
            "  Validation loss did not improve. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - 2490s - Train Loss: 0.0959, Train Acc: 0.9623 - Val Loss: 0.2334, Val Acc: 0.9260\n",
            "  Validation loss did not improve. Patience: 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - 2482s - Train Loss: 0.0819, Train Acc: 0.9688 - Val Loss: 0.1675, Val Acc: 0.9375\n",
            "  Validation loss decreased (0.2119 --> 0.1675). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - 2496s - Train Loss: 0.0652, Train Acc: 0.9749 - Val Loss: 0.2737, Val Acc: 0.9197\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - 2512s - Train Loss: 0.0566, Train Acc: 0.9773 - Val Loss: 0.2963, Val Acc: 0.9193\n",
            "  Validation loss did not improve. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - 2490s - Train Loss: 0.0545, Train Acc: 0.9774 - Val Loss: 0.2001, Val Acc: 0.9380\n",
            "  Validation loss did not improve. Patience: 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - 2497s - Train Loss: 0.0439, Train Acc: 0.9824 - Val Loss: 0.3015, Val Acc: 0.9123\n",
            "  Validation loss did not improve. Patience: 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - 2467s - Train Loss: 0.0376, Train Acc: 0.9856 - Val Loss: 0.2200, Val Acc: 0.9387\n",
            "  Validation loss did not improve. Patience: 5/5\n",
            "Early stopping triggered after 13 epochs.\n",
            "=== í•™ìŠµ ì™„ë£Œ ===\n",
            "\n",
            "=== í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€ ì‹œì‘ ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ =====\n",
            "  Test Loss: 0.1550\n",
            "  Test Accuracy: 93.95%\n",
            "ì´ ì‹¤í–‰ ì‹œê°„: 548.79 ë¶„\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    }
  ]
}