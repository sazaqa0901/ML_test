{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazaqa0901/ML_test/blob/main/deepfake_resnet_s_d_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYonvVA7wjeR"
      },
      "source": [
        "resnet50\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuQ-92WQx0En",
        "outputId": "90a1cded-93e4-4123-be45-9a98465b1320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_file_name = '/content/drive/MyDrive/archive.zip'\n",
        "extraction_dir = '/content/dataset'\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extraction_dir)"
      ],
      "metadata": {
        "id": "frg-vDR7x1IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJWtewChprMW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import time\n",
        "import copy\n",
        "\n",
        "\n",
        "# import h5py\n",
        "# import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfsznOINwjeX"
      },
      "outputs": [],
      "source": [
        "# 설정값\n",
        "IMG_SIZE = 224\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "NUM_SAMPLES = 20000\n",
        "LEARNING_RATE = 1e-4\n",
        "PATIENCE = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak9tUFkiwjeY"
      },
      "outputs": [],
      "source": [
        "# 이미지 전처리 클래스\n",
        "# 비율 유지하며 resize 후 패딩 추가(0으로)\n",
        "class ResizeWithPad:\n",
        "    def __init__(self, target_size):\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "\n",
        "        scale = self.target_size / max(w, h)\n",
        "\n",
        "        new_w = int(w * scale)\n",
        "        new_h = int(h * scale)\n",
        "\n",
        "        # 비율 유지하며 리사이즈\n",
        "        resized_img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "\n",
        "        # 검은색 캔버스 생성\n",
        "        canvas = Image.new(\"RGB\", (self.target_size, self.target_size), (0, 0, 0))\n",
        "\n",
        "        # 캔버스 중앙에 리사이즈된 이미지 배치\n",
        "        pad_x = (self.target_size - new_w) // 2\n",
        "        pad_y = (self.target_size - new_h) // 2\n",
        "\n",
        "        canvas.paste(resized_img, (pad_x, pad_y))\n",
        "\n",
        "        return canvas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpzKAxb3-neB"
      },
      "outputs": [],
      "source": [
        "# 데이터셋\n",
        "# 디스크의 이미지 경로 리스트를 받아,\n",
        "# 배치 생성 시점에만 이미지를 읽어옴\n",
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, paths, labels, transform=None):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 디스크에서 이미지 경로로 이미지 로드 (PIL)\n",
        "        img_path = self.paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # 전처리 적용\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # 라벨을 float 텐서로 변환 (BCEWithLogitsLoss용)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "        return image, label.unsqueeze(0) # (1,) 형태로 반환\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtDP02qNtpRB"
      },
      "outputs": [],
      "source": [
        "class AlexNetLike(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(AlexNetLike, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Conv 1\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2), # 224 -> 55\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 55 -> 27\n",
        "\n",
        "            # Conv 2\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2), # 27 -> 27\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 27 -> 13\n",
        "\n",
        "            # Conv 3\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv 4\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv 5\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 13 -> 6\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 6 * 6, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, num_classes) # num_classes=1\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x); x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1); x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqWWMXSPwjea"
      },
      "outputs": [],
      "source": [
        "def get_model(model_name, device, use_pretrained=True):\n",
        "\n",
        "    model = None\n",
        "    num_classes = 1 #이진 분류 (Real/Fake)\n",
        "\n",
        "    weights = models.ResNet50_Weights.IMAGENET1K_V1 if use_pretrained else None\n",
        "\n",
        "    print(f\"Loading {model_name} architecture...\")\n",
        "    if use_pretrained:\n",
        "        print(\"  Using ImageNet Pre-trained Weights.\")\n",
        "    else:\n",
        "        print(\"  Training FROM SCRATCH (No Pre-trained Weights).\")\n",
        "\n",
        "    if model_name.lower() == 'alexnet':\n",
        "        # 직접(동욱) 짠 AlexNet\n",
        "        model = AlexNetLike(num_classes=num_classes)\n",
        "        print(\"  Note: Using custom AlexNetLike, ignoring 'use_pretrained'.\")\n",
        "\n",
        "    elif model_name.lower() == 'vgg16':\n",
        "        model = models.vgg16(weights=weights if model_name.lower() == 'vgg16' else None)\n",
        "        num_ftrs = model.classifier[6].in_features\n",
        "        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    elif model_name.lower() == 'googlenet':\n",
        "        model = models.googlenet(weights=weights if model_name.lower() == 'googlenet' else None, num_classes=num_classes, aux_logits=False)\n",
        "\n",
        "    elif model_name.lower() == 'resnet50':\n",
        "        model = models.resnet50(weights=weights)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "        nn.Dropout(p=0.3),\n",
        "        nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {model_name}. Choose from 'alexnet', 'vgg16', 'googlenet', 'resnet50'\")\n",
        "\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H56_ULwNi61i"
      },
      "outputs": [],
      "source": [
        "# 학습\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs, patience):\n",
        "    print(\"=== 학습 시작 ===\")\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_weights = None\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # --- 훈련 ---\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        # tqdm으로 진행 상황 표시\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
        "\n",
        "        for images, labels in train_pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # 순전파\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 역전파 및 최적화\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # 정확도 계산\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "\n",
        "            train_pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_train_acc = correct_train / total_train\n",
        "\n",
        "        # --- 검증 ---\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
        "            for images, labels in val_pbar:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_val_loss += loss.item() * images.size(0)\n",
        "\n",
        "                preds = torch.sigmoid(outputs) > 0.5\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (preds == labels).sum().item()\n",
        "\n",
        "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
        "        epoch_val_acc = correct_val / total_val\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - {elapsed_time:.0f}s - \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f} - \"\n",
        "              f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
        "\n",
        "        # --- Early Stopping 및 Best Model 저장 ---\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            print(f\"  Validation loss decreased ({best_val_loss:.4f} --> {epoch_val_loss:.4f}). Saving model...\")\n",
        "            best_val_loss = epoch_val_loss\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model_weights, MODEL_SAVE_PATH)\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"  Validation loss did not improve. Patience: {epochs_no_improve}/{patience}\")\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "            break\n",
        "\n",
        "        scheduler.step(epoch_val_loss)\n",
        "\n",
        "    print(\"=== 학습 완료 ===\")\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df3H5EVywjeb"
      },
      "outputs": [],
      "source": [
        "# 평가\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_test_loss = 0.0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    print(\"\\n=== 테스트셋 평가 시작 ===\")\n",
        "    with torch.no_grad():\n",
        "        test_pbar = tqdm(test_loader, desc=\"[Test]\", leave=False)\n",
        "        for images, labels in test_pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_test_loss += loss.item() * images.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (preds == labels).sum().item()\n",
        "\n",
        "    test_loss = running_test_loss / len(test_loader.dataset)\n",
        "    test_acc = correct_test / total_test\n",
        "\n",
        "    print(f\"===== 최종 테스트 결과 =====\")\n",
        "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GKw1frNwjec",
        "outputId": "0251b585-b3d2-4165-f258-efca4b2a242c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "이미지 경로 수집 중...\n",
            "총 10905개 이미지 경로 발견.\n",
            "10000개 샘플을 샘플링...\n",
            "샘플링 완료: 10000개 이미지 선택.\n"
          ]
        }
      ],
      "source": [
        "# 메인 실행\n",
        "start_time = time.time()\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 데이터 경로 및 라벨 수집\n",
        "Fake_PATH = \"/content/dataset/real_fake_dataset/Test/face_fake\"\n",
        "Real_PATH = \"/content/dataset/real_fake_dataset/face_real\"\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/deepfake_model_1.pth\"\n",
        "print(\"이미지 경로 수집 중...\")\n",
        "face_real_dir = os.path.join(Real_PATH)\n",
        "face_fake_dir = os.path.join(Fake_PATH)\n",
        "\n",
        "real_paths = glob.glob(os.path.join(face_real_dir, \"*.*\"))\n",
        "fake_paths = glob.glob(os.path.join(face_fake_dir, \"*.*\"))\n",
        "\n",
        "all_paths = real_paths + fake_paths\n",
        "all_labels = [0] * len(real_paths) + [1] * len(fake_paths)\n",
        "\n",
        "print(f\"총 {len(all_labels)}개 이미지 경로 발견.\")\n",
        "\n",
        "# 20000개 샘플링\n",
        "print(f\"{NUM_SAMPLES}개 샘플을 샘플링...\")\n",
        "_, target_paths, _, target_labels = train_test_split(\n",
        "    all_paths, all_labels,\n",
        "    test_size= NUM_SAMPLES,\n",
        "    random_state=42,\n",
        "    stratify=all_labels\n",
        ")\n",
        "print(f\"샘플링 완료: {len(target_labels)}개 이미지 선택.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRUieuirwjed",
        "outputId": "3cf158da-5933-4c70-e48d-9ae5495ef8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터를 7:2:1 비율로 분할합니다...\n",
            "분할 완료: Train 7000개, Validation 2000개, Test 1000개\n",
            "데이터 로더 생성 완료.\n"
          ]
        }
      ],
      "source": [
        "# 7:2:1 분할 (Keras와 동일)\n",
        "print(\"데이터를 7:2:1 비율로 분할합니다...\")\n",
        "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "    target_paths, target_labels, test_size=0.3, random_state=42, stratify=target_labels\n",
        ")\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "    temp_paths, temp_labels, test_size=(1/3), random_state=42, stratify=temp_labels\n",
        ")\n",
        "print(f\"분할 완료: Train {len(train_paths)}개, Validation {len(val_paths)}개, Test {len(test_paths)}개\")\n",
        "\n",
        "# 전처리 및 데이터 로더 정의\n",
        "train_transform = transforms.Compose([\n",
        "    ResizeWithPad(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(), # 데이터 증강\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # -1 ~ 1 정규화\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    ResizeWithPad(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "train_dataset = DeepfakeDataset(train_paths, train_labels, transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(val_paths, val_labels, transform=val_test_transform)\n",
        "test_dataset = DeepfakeDataset(test_paths, test_labels, transform=val_test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "\n",
        "print(\"데이터 로더 생성 완료.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4_5lk7hwjed",
        "outputId": "10c03163-8e11-494e-bd41-8039a27c882a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 로더(디스크 기반)를 사용하여 학습을 시작합니다.\n",
            "Loading resnet50 architecture...\n",
            "  Using ImageNet Pre-trained Weights.\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 132MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 학습 시작 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - 69s - Train Loss: 0.6889, Train Acc: 0.5450 - Val Loss: 0.6676, Val Acc: 0.6055\n",
            "  Validation loss decreased (inf --> 0.6676). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - 62s - Train Loss: 0.6540, Train Acc: 0.6156 - Val Loss: 0.6380, Val Acc: 0.6630\n",
            "  Validation loss decreased (0.6676 --> 0.6380). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - 63s - Train Loss: 0.6310, Train Acc: 0.6537 - Val Loss: 0.6201, Val Acc: 0.6685\n",
            "  Validation loss decreased (0.6380 --> 0.6201). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - 63s - Train Loss: 0.6151, Train Acc: 0.6703 - Val Loss: 0.6072, Val Acc: 0.6835\n",
            "  Validation loss decreased (0.6201 --> 0.6072). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - 62s - Train Loss: 0.6020, Train Acc: 0.6919 - Val Loss: 0.5949, Val Acc: 0.7000\n",
            "  Validation loss decreased (0.6072 --> 0.5949). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - 62s - Train Loss: 0.5912, Train Acc: 0.6914 - Val Loss: 0.5862, Val Acc: 0.7040\n",
            "  Validation loss decreased (0.5949 --> 0.5862). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - 62s - Train Loss: 0.5831, Train Acc: 0.6963 - Val Loss: 0.5781, Val Acc: 0.7135\n",
            "  Validation loss decreased (0.5862 --> 0.5781). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - 62s - Train Loss: 0.5764, Train Acc: 0.7077 - Val Loss: 0.5729, Val Acc: 0.7160\n",
            "  Validation loss decreased (0.5781 --> 0.5729). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - 62s - Train Loss: 0.5735, Train Acc: 0.7103 - Val Loss: 0.5671, Val Acc: 0.7165\n",
            "  Validation loss decreased (0.5729 --> 0.5671). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - 64s - Train Loss: 0.5659, Train Acc: 0.7137 - Val Loss: 0.5629, Val Acc: 0.7220\n",
            "  Validation loss decreased (0.5671 --> 0.5629). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - 62s - Train Loss: 0.5622, Train Acc: 0.7136 - Val Loss: 0.5588, Val Acc: 0.7250\n",
            "  Validation loss decreased (0.5629 --> 0.5588). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - 62s - Train Loss: 0.5606, Train Acc: 0.7119 - Val Loss: 0.5563, Val Acc: 0.7275\n",
            "  Validation loss decreased (0.5588 --> 0.5563). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - 62s - Train Loss: 0.5555, Train Acc: 0.7194 - Val Loss: 0.5520, Val Acc: 0.7295\n",
            "  Validation loss decreased (0.5563 --> 0.5520). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - 62s - Train Loss: 0.5525, Train Acc: 0.7206 - Val Loss: 0.5493, Val Acc: 0.7285\n",
            "  Validation loss decreased (0.5520 --> 0.5493). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - 62s - Train Loss: 0.5517, Train Acc: 0.7163 - Val Loss: 0.5476, Val Acc: 0.7330\n",
            "  Validation loss decreased (0.5493 --> 0.5476). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - 62s - Train Loss: 0.5507, Train Acc: 0.7237 - Val Loss: 0.5444, Val Acc: 0.7275\n",
            "  Validation loss decreased (0.5476 --> 0.5444). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - 62s - Train Loss: 0.5465, Train Acc: 0.7267 - Val Loss: 0.5414, Val Acc: 0.7280\n",
            "  Validation loss decreased (0.5444 --> 0.5414). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - 62s - Train Loss: 0.5473, Train Acc: 0.7234 - Val Loss: 0.5395, Val Acc: 0.7340\n",
            "  Validation loss decreased (0.5414 --> 0.5395). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - 62s - Train Loss: 0.5434, Train Acc: 0.7253 - Val Loss: 0.5381, Val Acc: 0.7305\n",
            "  Validation loss decreased (0.5395 --> 0.5381). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 - 62s - Train Loss: 0.5424, Train Acc: 0.7307 - Val Loss: 0.5370, Val Acc: 0.7355\n",
            "  Validation loss decreased (0.5381 --> 0.5370). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 - 63s - Train Loss: 0.5394, Train Acc: 0.7306 - Val Loss: 0.5348, Val Acc: 0.7305\n",
            "  Validation loss decreased (0.5370 --> 0.5348). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 - 62s - Train Loss: 0.5371, Train Acc: 0.7276 - Val Loss: 0.5336, Val Acc: 0.7335\n",
            "  Validation loss decreased (0.5348 --> 0.5336). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30 - 62s - Train Loss: 0.5358, Train Acc: 0.7323 - Val Loss: 0.5322, Val Acc: 0.7340\n",
            "  Validation loss decreased (0.5336 --> 0.5322). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30 - 62s - Train Loss: 0.5360, Train Acc: 0.7304 - Val Loss: 0.5307, Val Acc: 0.7320\n",
            "  Validation loss decreased (0.5322 --> 0.5307). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30 - 62s - Train Loss: 0.5331, Train Acc: 0.7356 - Val Loss: 0.5289, Val Acc: 0.7335\n",
            "  Validation loss decreased (0.5307 --> 0.5289). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30 - 62s - Train Loss: 0.5354, Train Acc: 0.7330 - Val Loss: 0.5295, Val Acc: 0.7355\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/30 - 61s - Train Loss: 0.5335, Train Acc: 0.7316 - Val Loss: 0.5274, Val Acc: 0.7355\n",
            "  Validation loss decreased (0.5289 --> 0.5274). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/30 - 62s - Train Loss: 0.5333, Train Acc: 0.7331 - Val Loss: 0.5309, Val Acc: 0.7335\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/30 - 62s - Train Loss: 0.5324, Train Acc: 0.7347 - Val Loss: 0.5256, Val Acc: 0.7420\n",
            "  Validation loss decreased (0.5274 --> 0.5256). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30 - 62s - Train Loss: 0.5266, Train Acc: 0.7354 - Val Loss: 0.5227, Val Acc: 0.7370\n",
            "  Validation loss decreased (0.5256 --> 0.5227). Saving model...\n",
            "=== 학습 완료 ===\n",
            "\n",
            "=== 테스트셋 평가 시작 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 최종 테스트 결과 =====\n",
            "  Test Loss: 0.5088\n",
            "  Test Accuracy: 75.40%\n",
            "총 실행 시간: 31.69 분\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print(\"데이터 로더(디스크 기반)를 사용하여 학습을 시작합니다.\")\n",
        "\n",
        "# 모델, 손실함수, 옵티마이저 정의\n",
        "MODEL_NAME = 'resnet50' # 사용할 모델\n",
        "#use_pretrained 사용\n",
        "model = get_model(MODEL_NAME, device, use_pretrained=True)\n",
        "\n",
        "# 모든 파라미터를 동결\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    #verbose=True\n",
        ")\n",
        "\n",
        "#학습 및 평가\n",
        "model = train_model(model, train_loader, val_loader, criterion, optimizer, device, EPOCHS, PATIENCE)\n",
        "\n",
        "evaluate_model(model, test_loader, criterion, device)\n",
        "\n",
        "print(f\"총 실행 시간: {(time.time() - start_time) / 60:.2f} 분\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}