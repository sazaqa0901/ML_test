{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazaqa0901/ML_test/blob/main/deepfake_alexnett0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnqheqHp_eJ7",
        "outputId": "2b33d675-eb51-43fb-8a80-cc508375bc28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_file_name = '/content/drive/MyDrive/Dataset.zip'\n",
        "extraction_dir = '/content/dataset'\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extraction_dir)"
      ],
      "metadata": {
        "id": "_yFfwAK-_eH2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import zipfile\n",
        "import time\n",
        "import copy"
      ],
      "metadata": {
        "id": "oomgwmXh_eMB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 전처리 클래스\n",
        "# 비율 유지하며 resize 후 패딩 추가(0으로)\n",
        "class ResizeWithPad:\n",
        "    def __init__(self, target_size):\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "\n",
        "        scale = self.target_size / max(w, h)\n",
        "\n",
        "        new_w = int(w * scale)\n",
        "        new_h = int(h * scale)\n",
        "\n",
        "        # 비율 유지하며 리사이즈\n",
        "        resized_img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "\n",
        "        # 검은색 캔버스 생성\n",
        "        canvas = Image.new(\"RGB\", (self.target_size, self.target_size), (0, 0, 0))\n",
        "\n",
        "        # 캔버스 중앙에 리사이즈된 이미지 배치\n",
        "        pad_x = (self.target_size - new_w) // 2\n",
        "        pad_y = (self.target_size - new_h) // 2\n",
        "\n",
        "        canvas.paste(resized_img, (pad_x, pad_y))\n",
        "\n",
        "        return canvas"
      ],
      "metadata": {
        "id": "r04pnWyL_eGB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋\n",
        "# 디스크의 이미지 경로 리스트를 받아,\n",
        "# 배치 생성 시점에만 이미지를 읽어옴\n",
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, paths, labels, transform=None):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 디스크에서 이미지 경로로 이미지 로드 (PIL)\n",
        "        img_path = self.paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # 전처리 적용\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # 라벨을 float 텐서로 변환 (BCEWithLogitsLoss용)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "        return image, label.unsqueeze(0) # (1,) 형태로 반환"
      ],
      "metadata": {
        "id": "5cnKs7Y4_eD8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNetLike(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(AlexNetLike, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Conv 1\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2), # 224 -> 55\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 55 -> 27\n",
        "\n",
        "            # Conv 2\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2), # 27 -> 27\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 27 -> 13\n",
        "\n",
        "            # Conv 3\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv 4\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv 5\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1), # 13 -> 13\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 13 -> 6\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 6 * 6, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, num_classes) # num_classes=1\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x); x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1); x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "umPNzLmK_eBl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model_name, device, use_pretrained=True):\n",
        "\n",
        "    model = None\n",
        "    num_classes = 1 #이진 분류 (Real/Fake)\n",
        "\n",
        "    weights = models.ResNet50_Weights.IMAGENET1K_V1 if use_pretrained else None\n",
        "\n",
        "    print(f\"Loading {model_name} architecture...\")\n",
        "    if use_pretrained:\n",
        "        print(\"  Using ImageNet Pre-trained Weights.\")\n",
        "    else:\n",
        "        print(\"  Training FROM SCRATCH (No Pre-trained Weights).\")\n",
        "\n",
        "    if model_name.lower() == 'alexnet':\n",
        "        # 직접(동욱) 짠 AlexNet\n",
        "        model = AlexNetLike(num_classes=num_classes)\n",
        "        print(\"  Note: Using custom AlexNetLike, ignoring 'use_pretrained'.\")\n",
        "\n",
        "    elif model_name.lower() == 'vgg16':\n",
        "        model = models.vgg16(weights=weights if model_name.lower() == 'vgg16' else None)\n",
        "        num_ftrs = model.classifier[6].in_features\n",
        "        model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    elif model_name.lower() == 'googlenet':\n",
        "        model = models.googlenet(weights=weights if model_name.lower() == 'googlenet' else None, num_classes=num_classes, aux_logits=False)\n",
        "\n",
        "    elif model_name.lower() == 'resnet50':\n",
        "        model = models.resnet50(weights=weights)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(num_ftrs, num_classes)\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {model_name}. Choose from 'alexnet', 'vgg16', 'googlenet', 'resnet50'\")\n",
        "\n",
        "    return model.to(device)"
      ],
      "metadata": {
        "id": "e0Qp3gIGDemx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs, patience):\n",
        "    print(\"=== 학습 시작 ===\")\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_weights = None\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # --- 훈련 ---\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        # tqdm으로 진행 상황 표시\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
        "\n",
        "        for images, labels in train_pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # 순전파\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 역전파 및 최적화\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # 정확도 계산\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "\n",
        "            train_pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_train_acc = correct_train / total_train\n",
        "\n",
        "        # --- 검증 ---\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
        "            for images, labels in val_pbar:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_val_loss += loss.item() * images.size(0)\n",
        "\n",
        "                preds = torch.sigmoid(outputs) > 0.5\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (preds == labels).sum().item()\n",
        "\n",
        "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
        "        epoch_val_acc = correct_val / total_val\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - {elapsed_time:.0f}s - \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f} - \"\n",
        "              f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
        "\n",
        "        # --- Early Stopping 및 Best Model 저장 ---\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            print(f\"  Validation loss decreased ({best_val_loss:.4f} --> {epoch_val_loss:.4f}). Saving model...\")\n",
        "            best_val_loss = epoch_val_loss\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model_weights, MODEL_SAVE_PATH)\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"  Validation loss did not improve. Patience: {epochs_no_improve}/{patience}\")\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "            break\n",
        "\n",
        "    print(\"=== 학습 완료 ===\")\n",
        "    model.load_state_dict(best_model_weights)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Qr4QQrf8DejZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_test_loss = 0.0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    print(\"\\n=== 테스트셋 평가 시작 ===\")\n",
        "    with torch.no_grad():\n",
        "        test_pbar = tqdm(test_loader, desc=\"[Test]\", leave=False)\n",
        "        for images, labels in test_pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_test_loss += loss.item() * images.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs) > 0.5\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (preds == labels).sum().item()\n",
        "\n",
        "    test_loss = running_test_loss / len(test_loader.dataset)\n",
        "    test_acc = correct_test / total_test\n",
        "\n",
        "    print(f\"===== 최종 테스트 결과 =====\")\n",
        "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "6C5ayqMnDeQ7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 path 만들기\n",
        "def load_and_sample(real_dir, fake_dir, n_samples=None):\n",
        "    real_paths = []\n",
        "    fake_paths = []\n",
        "\n",
        "    real_paths.extend(glob.glob(os.path.join(real_dir, \"*.*\")))\n",
        "    fake_paths.extend(glob.glob(os.path.join(fake_dir, \"*.*\")))\n",
        "\n",
        "    paths = real_paths + fake_paths\n",
        "    labels = [0] * len(real_paths) + [1] * len(fake_paths)\n",
        "    total = len(paths)\n",
        "\n",
        "    print(f\"경로: {os.path.dirname(real_dir)}\")\n",
        "    print(f\"개수: {total}장 (Real: {len(real_paths)}, Fake: {len(fake_paths)})\")\n",
        "\n",
        "    if n_samples is None or n_samples >= total:\n",
        "        print(f\"  - 전체 데이터 사용 ({total}장)\")\n",
        "        # 셔플만 수행\n",
        "        combined = list(zip(paths, labels))\n",
        "        np.random.shuffle(combined)\n",
        "        paths[:], labels[:] = zip(*combined)\n",
        "        return paths, labels\n",
        "\n",
        "    else:\n",
        "        print(f\"  - 샘플링: {n_samples}장 선택 (Stratified)\")\n",
        "\n",
        "        sampled_paths, _, sampled_labels, _ = train_test_split(\n",
        "            paths, labels,\n",
        "            train_size=n_samples,\n",
        "            stratify=labels,\n",
        "            random_state=42\n",
        "        )\n",
        "        return sampled_paths, sampled_labels"
      ],
      "metadata": {
        "id": "N43ct3Le_d_f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메인 실행\n",
        "start_time = time.time()\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 데이터 경로 및 라벨 수집\n",
        "base_path = \"/content/dataset/Dataset/\"\n",
        "train_path = base_path + 'Train'\n",
        "validdation_path = base_path + 'Validation'\n",
        "test_path = base_path + 'Test'\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/deepfake_model.pth\"\n",
        "\n",
        "NUM_TRAIN_SAMPLES = 14000\n",
        "NUM_VAL_SAMPLES = 4000\n",
        "NUM_TEST_SAMPLES = 2000    # None: 전체 사용\n",
        "\n",
        "print(\"\\n=== [Train Set] 준비 ===\")\n",
        "train_paths, train_labels = load_and_sample(\n",
        "    os.path.join(train_path, 'Real'),\n",
        "    os.path.join(train_path, 'Fake'),\n",
        "    NUM_TRAIN_SAMPLES\n",
        ")\n",
        "\n",
        "print(\"\\n=== [Validation Set] 준비 ===\")\n",
        "val_paths, val_labels = load_and_sample(\n",
        "    os.path.join(validdation_path, 'Real'),\n",
        "    os.path.join(validdation_path, 'Fake'),\n",
        "    NUM_VAL_SAMPLES\n",
        ")\n",
        "\n",
        "print(\"\\n=== [Test Set] 준비 ===\")\n",
        "test_paths, test_labels = load_and_sample(\n",
        "    os.path.join(test_path, 'Real'),\n",
        "    os.path.join(test_path, 'Fake'),\n",
        "    NUM_TEST_SAMPLES\n",
        ")\n",
        "\n",
        "#target_labels = list(set((train_labels + val_labels + test_labels)))\n",
        "\n",
        "# 4. 결과 확인\n",
        "print(f\"\\n최종 데이터셋 구성:\")\n",
        "print(f\"  Train: {len(train_paths)}장\")\n",
        "print(f\"  Val  : {len(val_paths)}장\")\n",
        "print(f\"  Test : {len(test_paths)}장\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqHsUNf__d9S",
        "outputId": "4f1c1eef-d2a5-4aeb-e3eb-1dc235146e08"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "=== [Train Set] 준비 ===\n",
            "경로: /content/dataset/Dataset/Train\n",
            "개수: 140002장 (Real: 70001, Fake: 70001)\n",
            "  - 샘플링: 14000장 선택 (Stratified)\n",
            "\n",
            "=== [Validation Set] 준비 ===\n",
            "경로: /content/dataset/Dataset/Validation\n",
            "개수: 39428장 (Real: 19787, Fake: 19641)\n",
            "  - 샘플링: 4000장 선택 (Stratified)\n",
            "\n",
            "=== [Test Set] 준비 ===\n",
            "경로: /content/dataset/Dataset/Test\n",
            "개수: 10905장 (Real: 5413, Fake: 5492)\n",
            "  - 샘플링: 2000장 선택 (Stratified)\n",
            "\n",
            "최종 데이터셋 구성:\n",
            "  Train: 14000장\n",
            "  Val  : 4000장\n",
            "  Test : 2000장\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 설정값\n",
        "IMG_SIZE = 224\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "NUM_SAMPLES = 20000\n",
        "LEARNING_RATE = 1e-4\n",
        "PATIENCE = 5"
      ],
      "metadata": {
        "id": "uDdvFlAyKtHX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 로더 정의\n",
        "train_transform = transforms.Compose([\n",
        "    ResizeWithPad(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
        "    transforms.RandomRotation(degrees=5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) ])\n",
        "val_test_transform = transforms.Compose([\n",
        "    ResizeWithPad(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "train_dataset = DeepfakeDataset(train_paths, train_labels, transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(val_paths, val_labels, transform=val_test_transform)\n",
        "test_dataset = DeepfakeDataset(test_paths, test_labels, transform=val_test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "\n",
        "print(\"데이터 로더 생성 완료.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpDi-KIoJh5z",
        "outputId": "437c4038-997c-425d-fb81-512fe31f5d38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 로더 생성 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_Cs4LZeZ2F3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccf4e49-a8d6-4a30-9ddb-37bf7997863a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 로드(디스크 기반)을 사용하여 학습을 시작합니다.\n",
            "Loading alexnet architecture...\n",
            "  Training FROM SCRATCH (No Pre-trained Weights).\n",
            "  Note: Using custom AlexNetLike, ignoring 'use_pretrained'.\n",
            "=== 학습 시작 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - 187s - Train Loss: 0.5641, Train Acc: 0.7006 - Val Loss: 0.5620, Val Acc: 0.7107\n",
            "  Validation loss decreased (inf --> 0.5620). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - 206s - Train Loss: 0.3425, Train Acc: 0.8493 - Val Loss: 0.5219, Val Acc: 0.7805\n",
            "  Validation loss decreased (0.5620 --> 0.5219). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - 171s - Train Loss: 0.2408, Train Acc: 0.8991 - Val Loss: 0.3195, Val Acc: 0.8715\n",
            "  Validation loss decreased (0.5219 --> 0.3195). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - 171s - Train Loss: 0.2038, Train Acc: 0.9159 - Val Loss: 0.4084, Val Acc: 0.8210\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - 170s - Train Loss: 0.1734, Train Acc: 0.9286 - Val Loss: 0.2777, Val Acc: 0.8755\n",
            "  Validation loss decreased (0.3195 --> 0.2777). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - 171s - Train Loss: 0.1534, Train Acc: 0.9364 - Val Loss: 0.2602, Val Acc: 0.8972\n",
            "  Validation loss decreased (0.2777 --> 0.2602). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - 171s - Train Loss: 0.1371, Train Acc: 0.9451 - Val Loss: 0.2286, Val Acc: 0.8998\n",
            "  Validation loss decreased (0.2602 --> 0.2286). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - 171s - Train Loss: 0.1265, Train Acc: 0.9471 - Val Loss: 0.2439, Val Acc: 0.9100\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - 169s - Train Loss: 0.1196, Train Acc: 0.9511 - Val Loss: 0.3158, Val Acc: 0.8645\n",
            "  Validation loss did not improve. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - 169s - Train Loss: 0.1053, Train Acc: 0.9596 - Val Loss: 0.3058, Val Acc: 0.8922\n",
            "  Validation loss did not improve. Patience: 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - 169s - Train Loss: 0.1000, Train Acc: 0.9611 - Val Loss: 0.2477, Val Acc: 0.9048\n",
            "  Validation loss did not improve. Patience: 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - 169s - Train Loss: 0.0915, Train Acc: 0.9639 - Val Loss: 0.1950, Val Acc: 0.9223\n",
            "  Validation loss decreased (0.2286 --> 0.1950). Saving model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - 170s - Train Loss: 0.0867, Train Acc: 0.9659 - Val Loss: 0.2143, Val Acc: 0.9245\n",
            "  Validation loss did not improve. Patience: 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - 170s - Train Loss: 0.0777, Train Acc: 0.9672 - Val Loss: 0.2759, Val Acc: 0.9005\n",
            "  Validation loss did not improve. Patience: 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - 170s - Train Loss: 0.0737, Train Acc: 0.9694 - Val Loss: 0.2423, Val Acc: 0.9135\n",
            "  Validation loss did not improve. Patience: 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - 169s - Train Loss: 0.0750, Train Acc: 0.9709 - Val Loss: 0.2079, Val Acc: 0.9275\n",
            "  Validation loss did not improve. Patience: 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - 170s - Train Loss: 0.0636, Train Acc: 0.9723 - Val Loss: 0.1962, Val Acc: 0.9280\n",
            "  Validation loss did not improve. Patience: 5/5\n",
            "Early stopping triggered after 17 epochs.\n",
            "=== 학습 완료 ===\n",
            "\n",
            "=== 테스트셋 평가 시작 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 최종 테스트 결과 =====\n",
            "  Test Loss: 0.2736\n",
            "  Test Accuracy: 88.45%\n",
            "총 실행 시간:  49.38 분\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "print(\"데이터 로드(디스크 기반)을 사용하여 학습을 시작합니다.\")\n",
        "\n",
        "#모델\n",
        "MODEL_NAME = \"alexnet\"\n",
        "model = get_model(MODEL_NAME, device, use_pretrained=False)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "#학습 및 평가\n",
        "model = train_model(model, train_loader, val_loader, criterion, optimizer, device, EPOCHS, PATIENCE)\n",
        "evaluate_model(model, test_loader, criterion, device)\n",
        "\n",
        "print(f\"총 실행 시간: {(time.time() - start_time) / 60: .2f} 분\")"
      ]
    }
  ]
}